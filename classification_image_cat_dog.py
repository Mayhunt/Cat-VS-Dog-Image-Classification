# -*- coding: utf-8 -*-
"""PredictImage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nfj8i8gVku7RcssT5d8cYSC1E2iLXmIv

# Import Libralies and create function
"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow import keras
from keras import models
from keras import layers
from keras import optimizers
from keras import callbacks
from keras import backend as K
from keras.preprocessing import image
from keras.datasets import fashion_mnist
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from keras.utils import np_utils
from keras.layers.convolutional import  MaxPooling2D
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from keras.preprocessing.image import ImageDataGenerator, load_img
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2
import os

# %load _utils
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from keras import backend as K

# Test
def print_hello():
    print('Hello')

# define a function to plot the result from training step
def show_result(history): 
    
    # Print the result from the last epoch
    print('Last train accuracy: %s'%history.history['acc'][-1])
    print('Last validation accuracy: %s'%history.history['val_acc'][-1])
    
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    
    epochs = range(1, len(loss) + 1)   
    
    # Define a subplot 
    fig, axs = plt.subplots(1,2,figsize=(15,4))
    
    # Plot loss
    loss_plot = axs[0]
    
    loss_plot.plot(epochs, loss, 'c--', label='Training loss')
    loss_plot.plot(epochs, val_loss, 'b', label='Validation loss')
    loss_plot.set_title('Training and validation loss')
    loss_plot.set_xlabel('Epochs')
    loss_plot.set_ylabel('Loss')
    loss_plot.legend()
    
    # Plot accuracy
    acc_plot = axs[1]
    
    acc_plot.plot(epochs, acc, 'c--', label='Training acc')
    acc_plot.plot(epochs, val_acc, 'b', label='Validation acc')
    acc_plot.set_title('Training and validation accuracy')
    acc_plot.set_xlabel('Epochs')
    acc_plot.set_ylabel('Accuracy')
    acc_plot.legend()

            
# Show activation value of each layer
def show_layer_activation(activation, model,num_layer,num_row=16):
    layer_names = []
    for layer in model.layers[:num_layer]:
        layer_names.append(layer.name)

    images_per_row = num_row
    for layer_name, layer_activation in zip(layer_names,activation):
        n_features = layer_activation.shape[-1]

        size = layer_activation.shape[1]

        n_cols = n_features//images_per_row
        display_grid = np.zeros((size * n_cols, images_per_row * size))

        for col in range(n_cols):
            for row in range(images_per_row):
                channel_image = layer_activation[0,:,:,col*images_per_row + row]
                channel_image -= channel_image.mean()
                channel_image /= channel_image.std()
                channel_image *= 64
                channel_image += 128
                channel_image = np.clip(channel_image, 0,255).astype('uint8')
                display_grid[col*size:(col +1)*size,
                             row*size:(row+1)*size] = channel_image
        scale = 1./size
        plt.figure(figsize=(scale*display_grid.shape[1],
                           scale*display_grid.shape[0]))
        plt.title(layer_name)
        plt.grid(False)
        plt.imshow(display_grid, aspect='auto', cmap='viridis')
        
        
def deprocess_image(img):
    
    # Zero-centering and make sure that std is 0.1
    img -= img.mean()
    img /= (img.std() + 1e-5)
    img *= 0.1
    
    # Clips to [0,1]
    img += 0.5
    img = np.clip(img,0,1)
    
    # Convert to RGB array
    img *= 255
    img = np.clip(img,0,255).astype('uint8')
    
    return img

def generate_pattern(model, layer_name , filter_index, size=150):
    # Build the loss function that maximize the activation of the nth filter of the layer under consideration
    layer_output = model.get_layer(layer_name).output
    loss = K.mean(layer_output[:,:,:,filter_index])
    
    # Compute the gradient of the input picture with regard to this loss
    grads = K.gradients(loss, model.input)[0]
    
    # Normalize the gradient
    grads /= (K.sqrt(K.mean(K.square(grads))) +1e-5)
    
    # Return the loss and gradient given the input picture
    iterate = K.function([model.input],[loss, grads])
    
    # Stars from a gray image with some noise
    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.
    
    # Run gradient ascent for 40 step
    step = 1.
    for i in range(40):
        loss_value, grads_value = iterate([input_img_data])
        input_img_data += grads_value * step
        
    img = input_img_data[0]
    return deprocess_image(img)

### feed layer name. ie, 'conv_1'
def visualize_filter(model,layer_name, size= 64, margin = 5):

    # Empty black image to store results
    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))

    # iterate over the row of result grid
    for i in range(8):
        # Iterate over the column of the result grid
        for j in range(8):
            # Generates the pattern for filter i + (j*8) in layer_name
            filter_img = generate_pattern(model, layer_name, i + (j*8), size=size)
            
            # Puts the result in the square (i,j) of the results grid
            horizontal_start = i * size + i * margin
            horizontal_end = horizontal_start + size
            vertical_start = j * size + j * margin
            vertical_end = vertical_start + size
            results[horizontal_start:horizontal_end,
                    vertical_start:vertical_end, :] = filter_img

    plt.figure(figsize=(20,20))
    plt.imshow(results)

"""# Load Data"""

!wget -c https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip
!unzip -qq Cat_Dog_data.zip

"""## View some sample image."""

import random
filenames_d = os.listdir("/content/Cat_Dog_data/train/dog")
sample = random.choice(filenames_d)
image = load_img("/content/Cat_Dog_data/train/dog/"+sample)
plt.imshow(image)

filenames_c = os.listdir("/content/Cat_Dog_data/train/cat")
sample = random.choice(filenames_c)
image = load_img("/content/Cat_Dog_data/train/cat/"+sample)
plt.imshow(image)

train_dir = '/content/Cat_Dog_data/train'
test_dir = '/content/Cat_Dog_data/test'

"""## 2.Preprocess Data"""

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2) # set validation split

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary',
    subset='training') # set as training data

validation_generator = train_datagen.flow_from_directory(
    train_dir, # same directory as training data
    target_size=(128, 128),
    batch_size=32,
    class_mode='binary',
    subset='validation') # set as validation data

test_datagen = ImageDataGenerator(rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(128, 128),
    batch_size=32,
    shuffle = False,
    class_mode='binary') # set as training data

"""# Baseline Model 1"""

IMG_WIDTH=128
IMG_HEIGHT=128
IMAGE_SIZE=(IMG_WIDTH, IMG_HEIGHT)
CHANNEL=3
BATCH_SIZE = 32
EPOCHS=5

cnn = models.Sequential()
cnn.add(layers.Conv2D(filters=32,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      kernel_initializer='he_normal',
                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL),
                      name = 'conv_1',
                     ))
cnn.add(layers.MaxPooling2D(2,2,name='max_pool_1'))
cnn.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_2',
                     ))
cnn.add(layers.MaxPooling2D(2,2,name='max_pool_2'))
cnn.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_3',
                     ))
cnn.add(layers.MaxPooling2D(2,2,name='max_pool_3'))
cnn.add(layers.Dropout(0.25,name='dropout_1'))
cnn.add(layers.Flatten())
cnn.add(layers.Dense(512,activation='relu',
                     name='fully_connect_1'
                    ))
cnn.add(layers.Dropout(0.5,name='dropout_2'))
cnn.add(layers.Dense(2,activation='softmax',
                     name='output'
                    ))
cnn.compile(optimizer='adam',
           loss = 'sparse_categorical_crossentropy',
           metrics=['acc'])
cnn.save('baseline_model.h5')
cnn.summary()

early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)
history = cnn.fit(train_generator,
                  steps_per_epoch = train_generator.samples // BATCH_SIZE,
                  validation_data = validation_generator, 
                  validation_steps = validation_generator.samples // BATCH_SIZE,
                  epochs = 5, callbacks=[early_stop])
cnn.save('baseline_model_itr20_early.h5')

show_result(history)

"""## Predict Test Set"""

# Calculate result
result = cnn.evaluate(test_generator,verbose=False)
# Predict and convert into a class
pred_class = cnn.predict(test_generator).argmax(axis=1)
labels =  test_generator.labels
# Show report
print(confusion_matrix(labels,pred_class))
print(classification_report(labels,pred_class))
print("Loss: %s Accuracy: %s" %(result[0],result[1]))

from random import shuffle
from skimage import io

f, ax = plt.subplots(2,5, figsize = (20, 20))
for i in range(0,10):
    img = io.imread(test_dir +'/'+ test_generator.filenames[i])
    predicted_class = "Dog" if pred_class[i] else "Cat"

    ax[i//5, i%5].imshow(img)
    ax[i//5, i%5].axis('off')
    ax[i//5, i%5].set_title("Predicted:{}".format(predicted_class))    

plt.show()

"""#### Predict Custom"""

import numpy as np
def predict_image(img_self):
  results={0:'cat',1:'dog'}
  # load the image
  im=load_img(img_self)
  # Resize image
  im=im.resize(IMAGE_SIZE)
  im=np.expand_dims(im,axis=0)
  # convert to array
  im=np.array(im)
  im=im/255
  #Predict
  predict=cnn.predict_classes([im])[0]
  print('\033[1m This is a {} '.format(results[predict]))
  image = load_img(img_self)
  plt.imshow(image)

"""# Try to change some hyperparameters in the model

**1. Change kernel_size from 3\*3 to 5\*5**
"""

cnn_1 = models.Sequential()
cnn_1.add(layers.Conv2D(filters=32,
                      kernel_size=(5,5),
                      padding='same',
                      activation = 'relu',
                      kernel_initializer='he_normal',
                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL),
                      name = 'conv_1',
                     ))
cnn_1.add(layers.MaxPooling2D(2,2,name='max_pool_1'))
cnn_1.add(layers.Conv2D(filters=64,
                      kernel_size=(5,5),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_2',
                     ))
cnn_1.add(layers.MaxPooling2D(2,2,name='max_pool_2'))
cnn_1.add(layers.Conv2D(filters=64,
                      kernel_size=(5,5),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_3',
                     ))
cnn_1.add(layers.MaxPooling2D(2,2,name='max_pool_3'))
cnn_1.add(layers.Dropout(0.25,name='dropout_1'))
cnn_1.add(layers.Flatten())
cnn_1.add(layers.Dense(512,activation='relu',
                     name='fully_connect_1'
                    ))
cnn_1.add(layers.Dropout(0.5,name='dropout_2'))
cnn_1.add(layers.Dense(2,activation='softmax',
                     name='output'
                    ))
cnn_1.compile(optimizer='adam',
           loss = 'sparse_categorical_crossentropy',
           metrics=['acc'])
cnn_1.save('tune_1.h5')
cnn_1.summary()

early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)
history_1 = cnn_1.fit(train_generator,
                  steps_per_epoch = train_generator.samples // BATCH_SIZE,
                  validation_data = validation_generator, 
                  validation_steps = validation_generator.samples // BATCH_SIZE,
                  epochs = 20,callbacks=[early_stop])
show_result(history_1)

result = cnn_1.evaluate(test_generator,verbose=False)

# Predict and convert into a class
pred_class = cnn_1.predict(test_generator).argmax(axis=1)
labels =  test_generator.labels
# Show report
print(confusion_matrix(labels,pred_class))
print(classification_report(labels,pred_class))
print("Loss: %s Accuracy: %s" %(result[0],result[1]))

""" **2. Change strides from 1\*1 to 2\*2**"""

cnn_2 = models.Sequential()
cnn_2.add(layers.Conv2D(filters=32,
                      kernel_size=(3,3),
                      strides=(2,2),
                      padding='same',
                      activation = 'relu',
                      kernel_initializer='he_normal',
                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL),
                      name = 'conv_1',
                     ))
cnn_2.add(layers.MaxPooling2D(2,2,name='max_pool_1'))
cnn_2.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      strides=(2,2),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_2',
                     ))
cnn_2.add(layers.MaxPooling2D(2,2,name='max_pool_2'))
cnn_2.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_3',
                     ))
cnn_2.add(layers.MaxPooling2D(2,2,name='max_pool_3'))
cnn_2.add(layers.Dropout(0.25,name='dropout_1'))
cnn_2.add(layers.Flatten())
cnn_2.add(layers.Dense(512,activation='relu',
                     name='fully_connect_1'
                    ))
cnn_2.add(layers.Dropout(0.5,name='dropout_2'))
cnn_2.add(layers.Dense(2,activation='softmax',
                     name='output'
                    ))
cnn_2.compile(optimizer='adam',
           loss = 'sparse_categorical_crossentropy',
           metrics=['acc'])
cnn_2.save('tune_2.h5')
cnn_2.summary()

early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)
history_2 = cnn_2.fit(train_generator,
                  steps_per_epoch = train_generator.samples // BATCH_SIZE,
                  validation_data = validation_generator, 
                  validation_steps = validation_generator.samples // BATCH_SIZE,
                  epochs = 20, callbacks=[early_stop])
show_result(history_2)

result = cnn_2.evaluate(test_generator,verbose=False)

# Predict and convert into a class
pred_class = cnn_2.predict(test_generator).argmax(axis=1)
labels =  test_generator.labels
# Show report
print(confusion_matrix(labels,pred_class))
print(classification_report(labels,pred_class))
print("Loss: %s Accuracy: %s" %(result[0],result[1]))

""" **3. Change filters to 32-64-128**"""

cnn_3 = models.Sequential()
cnn_3.add(layers.Conv2D(filters=32,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      kernel_initializer='he_normal',
                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL),
                      name = 'conv_1',
                     ))
cnn_3.add(layers.MaxPooling2D(2,2,name='max_pool_1'))
cnn_3.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_2',
                     ))
cnn_3.add(layers.MaxPooling2D(2,2,name='max_pool_2'))
cnn_3.add(layers.Conv2D(filters=128,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_3',
                     ))
cnn_3.add(layers.MaxPooling2D(2,2,name='max_pool_3'))
cnn_3.add(layers.Dropout(0.25,name='dropout_1'))
cnn_3.add(layers.Flatten())
cnn_3.add(layers.Dense(512,activation='relu',
                     name='fully_connect_1'
                    ))
cnn_3.add(layers.Dropout(0.5,name='dropout_2'))
cnn_3.add(layers.Dense(2,activation='softmax',
                     name='output'
                    ))
cnn_3.compile(optimizer='adam',
           loss = 'sparse_categorical_crossentropy',
           metrics=['acc'])
cnn_3.save('tune_3.h5')
cnn_3.summary()

early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)
history_3 = cnn_3.fit(train_generator,
                  steps_per_epoch = train_generator.samples // BATCH_SIZE,
                  validation_data = validation_generator, 
                  validation_steps = validation_generator.samples // BATCH_SIZE,
                  epochs = 20, callbacks=[early_stop])
show_result(history_3)

result = cnn_3.evaluate(test_generator,verbose=False)

# Predict and convert into a class
pred_class = cnn_3.predict(test_generator).argmax(axis=1)
labels =  test_generator.labels
# Show report
print(confusion_matrix(labels,pred_class))
print(classification_report(labels,pred_class))
print("Loss: %s Accuracy: %s" %(result[0],result[1]))

""" **4. Change last dense's softmax to sigmoid**"""

cnn_4 = models.Sequential()
cnn_4.add(layers.Conv2D(filters=32,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      kernel_initializer='he_normal',
                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL),
                      name = 'conv_1',
                     ))
cnn_4.add(layers.MaxPooling2D(2,2,name='max_pool_1'))
cnn_4.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_2',
                     ))
cnn_4.add(layers.MaxPooling2D(2,2,name='max_pool_2'))
cnn_4.add(layers.Conv2D(filters=64,
                      kernel_size=(3,3),
                      padding='same',
                      activation = 'relu',
                      name = 'conv_3',
                     ))
cnn_4.add(layers.MaxPooling2D(2,2,name='max_pool_3'))
cnn_4.add(layers.Dropout(0.25,name='dropout_1'))
cnn_4.add(layers.Flatten())
cnn_4.add(layers.Dense(512,activation='relu',
                     name='fully_connect_1'
                    ))
cnn_4.add(layers.Dropout(0.5,name='dropout_2'))
cnn_4.add(layers.Dense(2,activation='sigmoid',
                     name='output'
                    ))
cnn_4.compile(optimizer='adam',
           loss = 'sparse_categorical_crossentropy',
           metrics=['acc'])
cnn_4.save('tune_4.h5')
cnn_4.summary()

early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=2)
history_4 = cnn_4.fit(train_generator,
                  steps_per_epoch = train_generator.samples // BATCH_SIZE,
                  validation_data = validation_generator, 
                  validation_steps = validation_generator.samples // BATCH_SIZE,
                  epochs = 20, callbacks=[early_stop])
show_result(history_4)

result = cnn_4.evaluate(test_generator,verbose=False)

# Predict and convert into a class
pred_class = cnn_4.predict(test_generator).argmax(axis=1)
labels =  test_generator.labels
# Show report
print(confusion_matrix(labels,pred_class))
print(classification_report(labels,pred_class))
print("Loss: %s Accuracy: %s" %(result[0],result[1]))

"""# Predict Image"""

from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img

#img_self = image path
def predict_image(img_self):
  playfile = img_self

  # load the image
  img = load_img(playfile, target_size=IMAGE_SIZE)
  # convert to array
  img = img_to_array(img)
  # reshape into a single sample with 3 channels
  img = img.reshape(1, 128, 128, 3)
  result = cnn.predict(img)

  result_clean = np.argmax(result, axis = -1)

  if(result_clean == 1):
    predict = "cat"
  else:
    predict = "dog"

  print(predict)
  image = load_img(playfile)
  plt.imshow(image)

## predict_image('/content/Cat_Dog_data/tk.jpg')